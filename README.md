[![SVG Banners](https://svg-banners.vercel.app/api?type=origin&text1=CosyVoiceğŸ¤ &text2=Text-to-Speech%20ğŸ’–%20Large%20Language%20Model&width=800&height=210)](https://github.com/Akshay090/svg-banners)

## ğŸ‘‰ğŸ» CosyVoice ğŸ‘ˆğŸ»

**CosyVoice 3.0**: [æ¼”ç¤º](https://funaudiollm.github.io/cosyvoice3/); [è®ºæ–‡](https://arxiv.org/abs/2505.17589); [CV3-Eval](https://github.com/FunAudioLLM/CV3-Eval)

**CosyVoice 2.0**: [æ¼”ç¤º](https://funaudiollm.github.io/cosyvoice2/); [è®ºæ–‡](https://arxiv.org/abs/2412.10117); [ModelScope](https://www.modelscope.cn/studios/iic/CosyVoice2-0.5B); [HuggingFace](https://huggingface.co/spaces/FunAudioLLM/CosyVoice2-0.5B)

**CosyVoice 1.0**: [æ¼”ç¤º](https://fun-audio-llm.github.io); [è®ºæ–‡](https://funaudiollm.github.io/pdf/CosyVoice_v1.pdf); [ModelScope](https://www.modelscope.cn/studios/iic/CosyVoice-300M)

## äº®ç‚¹ğŸ”¥

**CosyVoice 2.0** å·²å‘å¸ƒï¼ç›¸æ¯” 1.0 ç‰ˆæœ¬ï¼Œæ–°ç‰ˆæœ¬æä¾›äº†æ›´å‡†ç¡®ã€æ›´ç¨³å®šã€æ›´å¿«ã€æ›´å¥½çš„è¯­éŸ³ç”Ÿæˆèƒ½åŠ›ã€‚

### å¤šè¯­è¨€æ”¯æŒ
- **æ”¯æŒè¯­è¨€**: ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€ä¸­æ–‡æ–¹è¨€ï¼ˆç²¤è¯­ã€å››å·è¯ã€ä¸Šæµ·è¯ã€å¤©æ´¥è¯ã€æ­¦æ±‰è¯ç­‰ï¼‰
- **è·¨è¯­è¨€å’Œæ··åˆè¯­è¨€**: æ”¯æŒè·¨è¯­è¨€å’Œä»£ç åˆ‡æ¢åœºæ™¯çš„é›¶æ ·æœ¬è¯­éŸ³å…‹éš†ã€‚

### è¶…ä½å»¶è¿Ÿ
- **åŒå‘æµå¼æ”¯æŒ**: CosyVoice 2.0 é›†æˆäº†ç¦»çº¿å’Œæµå¼å»ºæ¨¡æŠ€æœ¯ã€‚
- **å¿«é€Ÿé¦–åŒ…åˆæˆ**: åœ¨ä¿æŒé«˜è´¨é‡éŸ³é¢‘è¾“å‡ºçš„åŒæ—¶ï¼Œå»¶è¿Ÿä½è‡³ 150msã€‚

### é«˜å‡†ç¡®ç‡
- **æ”¹è¿›çš„å‘éŸ³**: ç›¸æ¯” CosyVoice 1.0ï¼Œå‘éŸ³é”™è¯¯ç‡é™ä½ 30% è‡³ 50%ã€‚
- **åŸºå‡†æµ‹è¯•æˆå°±**: åœ¨ Seed-TTS è¯„ä¼°é›†çš„å›°éš¾æµ‹è¯•é›†ä¸Šè¾¾åˆ°æœ€ä½å­—ç¬¦é”™è¯¯ç‡ã€‚

### å¼ºç¨³å®šæ€§
- **éŸ³è‰²ä¸€è‡´æ€§**: ç¡®ä¿é›¶æ ·æœ¬å’Œè·¨è¯­è¨€è¯­éŸ³åˆæˆçš„å¯é éŸ³è‰²ä¸€è‡´æ€§ã€‚
- **è·¨è¯­è¨€åˆæˆ**: ç›¸æ¯” 1.0 ç‰ˆæœ¬æœ‰æ˜¾è‘—æ”¹è¿›ã€‚

### è‡ªç„¶ä½“éªŒ
- **å¢å¼ºçš„éŸµå¾‹å’ŒéŸ³è´¨**: æ”¹è¿›äº†åˆæˆéŸ³é¢‘çš„å¯¹é½ï¼ŒMOS è¯„ä¼°åˆ†æ•°ä» 5.4 æå‡åˆ° 5.53ã€‚
- **æƒ…æ„Ÿå’Œæ–¹è¨€çµæ´»æ€§**: ç°åœ¨æ”¯æŒæ›´ç»†ç²’åº¦çš„æƒ…æ„Ÿæ§åˆ¶å’Œå£éŸ³è°ƒæ•´ã€‚

## è·¯çº¿å›¾

- [x] 2025/08
    - [x] æ„Ÿè°¢ NVIDIA Yuekai Zhang çš„è´¡çŒ®ï¼Œæ·»åŠ äº† triton trtllm è¿è¡Œæ—¶æ”¯æŒå’Œ cosyvoice2 grpo è®­ç»ƒæ”¯æŒ

- [x] 2025/07
    - [x] å‘å¸ƒ cosyvoice 3.0 è¯„ä¼°é›†

- [x] 2025/05
    - [x] æ·»åŠ  cosyvoice 2.0 vllm æ”¯æŒ

- [x] 2024/12
    - [x] 25hz cosyvoice 2.0 å‘å¸ƒ

- [x] 2024/09
    - [x] 25hz cosyvoice åŸºç¡€æ¨¡å‹
    - [x] 25hz cosyvoice è¯­éŸ³è½¬æ¢æ¨¡å‹

- [x] 2024/08
    - [x] ç”¨äº LLM ç¨³å®šæ€§çš„é‡å¤æ„ŸçŸ¥é‡‡æ ·(RAS)æ¨ç†
    - [x] æµå¼æ¨ç†æ¨¡å¼æ”¯æŒï¼ŒåŒ…æ‹¬ç”¨äº RTF ä¼˜åŒ–çš„ kv cache å’Œ sdpa

- [x] 2024/07
    - [x] Flow matching è®­ç»ƒæ”¯æŒ
    - [x] å½“ ttsfrd ä¸å¯ç”¨æ—¶æ”¯æŒ WeTextProcessing
    - [x] Fastapi æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯

## æ¨¡å‹å¯¹æ¯”åˆ†æ

### å¯ç”¨æ¨¡å‹æ¦‚è§ˆ

CosyVoice é¡¹ç›®æä¾›äº†å¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹é’ˆå¯¹ä¸åŒçš„ä½¿ç”¨åœºæ™¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†çš„æ¨¡å‹å¯¹æ¯”åˆ†æï¼š

| æ¨¡å‹ | å‚æ•°é‡ | æ¨èåº¦ | ä¸»è¦ç”¨é€” | æ˜¾å­˜éœ€æ±‚ | ç‰ˆæœ¬ |
|------|--------|--------|----------|----------|------|
| **CosyVoice2-0.5B** | 0.5B | â­â­â­â­â­ | é€šç”¨ï¼ˆæœ€ä½³æ€§èƒ½ï¼‰ | é«˜ | 2.0 |
| **CosyVoice-300M** | 300M | â­â­â­â­ | é›¶æ ·æœ¬ã€è·¨è¯­ç§ã€VC | ä¸­ | 1.0 |
| **CosyVoice-300M-SFT** | 300M | â­â­â­ | å›ºå®šéŸ³è‰²åœºæ™¯ | ä¸­ | 1.0 |
| **CosyVoice-300M-Instruct** | 300M | â­â­â­â­ | æƒ…æ„Ÿ/é£æ ¼æ§åˆ¶ | ä¸­ | 1.0 |
| **CosyVoice-300M-25Hz** | 300M | â­â­â­ | å®æ—¶/å¿«é€Ÿæ¨ç† | ä½ | 1.0 |

### åŠŸèƒ½æ”¯æŒçŸ©é˜µ

| åŠŸèƒ½ | CosyVoice2-0.5B | CosyVoice-300M | 300M-SFT | 300M-Instruct |
|------|------------------|----------------|----------|---------------|
| Zero-shot è¯­éŸ³å…‹éš† | âœ… | âœ… | âŒ | âŒ |
| è·¨è¯­ç§åˆæˆ | âœ… | âœ… | âŒ | âŒ |
| SFTï¼ˆé¢„è®­ç»ƒéŸ³è‰²ï¼‰ | âŒ | âŒ | âœ… | âœ… |
| Instruct è‡ªç„¶è¯­è¨€æ§åˆ¶ | âœ… (instruct2) | âŒ | âŒ | âœ… |
| è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰ | âŒ | âœ… | âŒ | âŒ |
| æµå¼æ¨ç† | âœ… | âœ… | âœ… | âœ… |

### è¯¦ç»†æ¨¡å‹åˆ†æ

#### 1. CosyVoice2-0.5B â­â­â­â­â­ï¼ˆæ¨èï¼‰

**ç‰ˆæœ¬**: CosyVoice 2.0  
**å‚æ•°é‡**: 0.5B  
**æ¶æ„**: åŸºäº Qwen2 çš„å¤§è¯­è¨€æ¨¡å‹

**ç‰¹ç‚¹**:
- âœ… **æœ€ä½³æ€§èƒ½**: å®˜æ–¹å¼ºçƒˆæ¨èï¼Œæ€§èƒ½æœ€ä¼˜
- âœ… **è¶…ä½å»¶è¿Ÿ**: é¦–åŒ…å»¶è¿Ÿä½è‡³ 150ms
- âœ… **é«˜å‡†ç¡®ç‡**: å‘éŸ³é”™è¯¯ç‡æ¯” 1.0 ç‰ˆæœ¬é™ä½ 30-50%
- âœ… **å¼ºç¨³å®šæ€§**: é›¶æ ·æœ¬å’Œè·¨è¯­è¨€åˆæˆç¨³å®šæ€§æ˜¾è‘—æå‡
- âœ… **æµå¼æ¨ç†**: æ”¯æŒåŒå‘æµå¼æ¨ç†
- âœ… **å¤šè¯­è¨€æ”¯æŒ**: ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€ä¸­æ–‡æ–¹è¨€ç­‰
- âœ… **é«˜è´¨é‡**: MOS è¯„åˆ† 5.53ï¼ˆ1.0 ç‰ˆæœ¬ä¸º 5.4ï¼‰

**æ”¯æŒçš„åŠŸèƒ½**:
- Zero-shot è¯­éŸ³å…‹éš†ï¼ˆ3s æé€Ÿå¤åˆ»ï¼‰
- è·¨è¯­ç§åˆæˆ
- ç»†ç²’åº¦æ§åˆ¶ï¼ˆå¦‚ `[laughter]` æ ‡è®°ï¼‰
- Instruct æ¨¡å¼ï¼ˆè‡ªç„¶è¯­è¨€æ§åˆ¶ï¼Œä½¿ç”¨ `inference_instruct2`ï¼‰
- åŒå‘æµå¼æ¨ç†

**ä¼˜ç‚¹**:
- âœ… æ€§èƒ½æœ€ä½³ï¼Œå‡†ç¡®ç‡æœ€é«˜
- âœ… å»¶è¿Ÿæœ€ä½ï¼Œé€‚åˆå®æ—¶åœºæ™¯
- âœ… ç¨³å®šæ€§å¼ºï¼ŒéŸ³è‰²ä¸€è‡´æ€§å¥½
- âœ… æ”¯æŒ vLLM åŠ é€Ÿæ¨ç†
- âœ… æ”¯æŒ TensorRT-LLM åŠ é€Ÿï¼ˆ4å€åŠ é€Ÿï¼‰

**ç¼ºç‚¹**:
- âŒ æ¨¡å‹è¾ƒå¤§ï¼ˆ0.5B vs 300Mï¼‰ï¼Œæ˜¾å­˜å ç”¨æ›´é«˜
- âŒ ä¸æ”¯æŒ `inference_instruct`ï¼ˆä»…æ”¯æŒ `inference_instruct2`ï¼‰
- âŒ ä¸æ”¯æŒè¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰åŠŸèƒ½

**é€‚ç”¨åœºæ™¯**: è¿½æ±‚æœ€ä½³æ€§èƒ½çš„é€šç”¨åœºæ™¯ï¼Œå®æ—¶è¯­éŸ³åˆæˆï¼Œé«˜è´¨é‡é›¶æ ·æœ¬å…‹éš†

---

#### 2. CosyVoice-300Mï¼ˆåŸºç¡€ç‰ˆï¼‰

**ç‰ˆæœ¬**: CosyVoice 1.0  
**å‚æ•°é‡**: 300M  
**æ¶æ„**: åŸºäº Transformer

**ç‰¹ç‚¹**:
- åŸºç¡€æ¨¡å‹ï¼ŒåŠŸèƒ½å®Œæ•´
- æ”¯æŒå¤šç§æ¨ç†æ¨¡å¼

**æ”¯æŒçš„åŠŸèƒ½**:
- Zero-shot è¯­éŸ³å…‹éš†
- è·¨è¯­ç§åˆæˆï¼ˆéœ€è¦ä½¿ç”¨è¯­è¨€æ ‡ç­¾å¦‚ `<|zh|>`, `<|en|>`ï¼‰
- è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰
- âŒ ä¸æ”¯æŒ SFT å’Œ Instructï¼ˆéœ€è¦ä½¿ç”¨å¯¹åº”çš„å˜ä½“æ¨¡å‹ï¼‰

**ä¼˜ç‚¹**:
- âœ… æ¨¡å‹è¾ƒå°ï¼Œæ˜¾å­˜å ç”¨ä½
- âœ… åŠŸèƒ½è¦†ç›–å…¨é¢
- âœ… æ”¯æŒè¯­éŸ³è½¬æ¢åŠŸèƒ½
- âœ… å…¼å®¹æ€§å¥½ï¼Œç¨³å®šå¯é 

**ç¼ºç‚¹**:
- âŒ æ€§èƒ½ä¸å¦‚ 2.0 ç‰ˆæœ¬
- âŒ å‡†ç¡®ç‡ç›¸å¯¹è¾ƒä½
- âŒ ä¸æ”¯æŒæµå¼æ¨ç†ä¼˜åŒ–
- âŒ ä¸æ”¯æŒ Instruct æ¨¡å¼

**é€‚ç”¨åœºæ™¯**: éœ€è¦è¯­éŸ³è½¬æ¢çš„åœºæ™¯ï¼Œèµ„æºå—é™çš„ç¯å¢ƒï¼ŒåŸºç¡€è¯­éŸ³åˆæˆéœ€æ±‚

---

#### 3. CosyVoice-300M-SFT

**ç‰ˆæœ¬**: CosyVoice 1.0  
**å‚æ•°é‡**: 300M  
**æ¶æ„**: åŸºäº Transformerï¼ˆSFT å¾®è°ƒç‰ˆæœ¬ï¼‰

**ç‰¹ç‚¹**:
- åŸºäº CosyVoice-300M çš„ SFTï¼ˆSupervised Fine-Tuningï¼‰å¾®è°ƒç‰ˆæœ¬
- å†…ç½®é¢„è®­ç»ƒéŸ³è‰²åº“

**æ”¯æŒçš„åŠŸèƒ½**:
- SFT æ¨¡å¼ï¼ˆä½¿ç”¨é¢„è®­ç»ƒéŸ³è‰²ï¼‰
- æ”¯æŒ `list_available_spks()` æŸ¥çœ‹å¯ç”¨éŸ³è‰²åˆ—è¡¨
- âŒ ä¸æ”¯æŒ Zero-shotã€è·¨è¯­ç§ã€VCã€Instruct

**ä¼˜ç‚¹**:
- âœ… é¢„è®­ç»ƒéŸ³è‰²è´¨é‡ç¨³å®šå¯é 
- âœ… æ— éœ€æä¾› prompt éŸ³é¢‘ï¼Œä½¿ç”¨æ–¹ä¾¿
- âœ… é€‚åˆå›ºå®šéŸ³è‰²åœºæ™¯

**ç¼ºç‚¹**:
- âŒ éŸ³è‰²é€‰æ‹©æœ‰é™ï¼Œåªèƒ½ä½¿ç”¨é¢„è®­ç»ƒéŸ³è‰²
- âŒ ä¸æ”¯æŒè‡ªå®šä¹‰éŸ³è‰²å…‹éš†
- âŒ ä¸æ”¯æŒè·¨è¯­ç§åˆæˆ

**é€‚ç”¨åœºæ™¯**: å›ºå®šéŸ³è‰²åœºæ™¯ï¼Œå®¢æœç³»ç»Ÿï¼Œæ ‡å‡†åŒ–è¯­éŸ³è¾“å‡º

---

#### 4. CosyVoice-300M-Instruct

**ç‰ˆæœ¬**: CosyVoice 1.0  
**å‚æ•°é‡**: 300M  
**æ¶æ„**: åŸºäº Transformerï¼ˆæŒ‡ä»¤å¾®è°ƒç‰ˆæœ¬ï¼‰

**ç‰¹ç‚¹**:
- åŸºäº CosyVoice-300M çš„æŒ‡ä»¤å¾®è°ƒç‰ˆæœ¬
- æ”¯æŒè‡ªç„¶è¯­è¨€æ§åˆ¶

**æ”¯æŒçš„åŠŸèƒ½**:
- Instruct æ¨¡å¼ï¼ˆè‡ªç„¶è¯­è¨€æ§åˆ¶ï¼‰
- æ”¯æŒæƒ…æ„Ÿã€è§’è‰²ç­‰ç»†ç²’åº¦æ§åˆ¶
- æ”¯æŒç‰¹æ®Šæ ‡è®°ï¼š`<laughter>`, `<strong>`, `[breath]` ç­‰
- æ”¯æŒ SFT æ¨¡å¼ï¼ˆä½¿ç”¨é¢„è®­ç»ƒéŸ³è‰²ï¼‰
- âŒ ä¸æ”¯æŒè·¨è¯­ç§ã€VC

**ä¼˜ç‚¹**:
- âœ… æ”¯æŒç»†ç²’åº¦æƒ…æ„Ÿå’Œé£æ ¼æ§åˆ¶
- âœ… å¯ä»¥é€šè¿‡æè¿°è§’è‰²ç‰¹å¾è¿›è¡Œæ§åˆ¶
- âœ… é€‚åˆéœ€è¦æƒ…æ„Ÿè¡¨è¾¾çš„åœºæ™¯

**ç¼ºç‚¹**:
- âŒ ä¸æ”¯æŒè·¨è¯­ç§åˆæˆ
- âŒ ä¸æ”¯æŒè¯­éŸ³è½¬æ¢
- âŒ éœ€è¦æä¾›è§’è‰²æè¿°æ–‡æœ¬

**é€‚ç”¨åœºæ™¯**: éœ€è¦æƒ…æ„Ÿæ§åˆ¶çš„åœºæ™¯ï¼Œè§’è‰²æ‰®æ¼”ï¼Œæœ‰å£°ä¹¦åˆ¶ä½œ

---

#### 5. CosyVoice-300M-25Hz

**ç‰ˆæœ¬**: CosyVoice 1.0ï¼ˆ25Hz å˜ä½“ï¼‰  
**å‚æ•°é‡**: 300M  
**æ¶æ„**: åŸºäº Transformerï¼ˆ25Hz å¸§ç‡ç‰ˆæœ¬ï¼‰

**ç‰¹ç‚¹**:
- 25Hz å¸§ç‡ç‰ˆæœ¬ï¼ˆæ ‡å‡†ç‰ˆæœ¬ä¸º 50Hzï¼‰
- æ¨ç†é€Ÿåº¦æ›´å¿«ï¼Œè´¨é‡ç•¥æœ‰ä¸‹é™

**ä¼˜ç‚¹**:
- âœ… æ¨ç†é€Ÿåº¦æ›´å¿«
- âœ… æ˜¾å­˜å ç”¨æ›´ä½
- âœ… é€‚åˆå®æ—¶åœºæ™¯

**ç¼ºç‚¹**:
- âŒ éŸ³è´¨å¯èƒ½ç•¥ä½äº 50Hz ç‰ˆæœ¬
- âŒ æ–‡æ¡£ä¸­ä¿¡æ¯è¾ƒå°‘

**é€‚ç”¨åœºæ™¯**: å®æ—¶è¯­éŸ³åˆæˆï¼Œèµ„æºå—é™ç¯å¢ƒï¼Œå¿«é€Ÿæ¨ç†éœ€æ±‚

---

#### 6. CosyVoice-ttsfrdï¼ˆèµ„æºæ–‡ä»¶ï¼‰

**ç±»å‹**: æ–‡æœ¬å¤„ç†èµ„æº  
**ç”¨é€”**: æ–‡æœ¬è§„èŒƒåŒ–

**ç‰¹ç‚¹**:
- éæ¨¡å‹æ–‡ä»¶ï¼Œæ˜¯æ–‡æœ¬å¤„ç†èµ„æº
- ç”¨äºæå‡æ–‡æœ¬è§„èŒƒåŒ–æ€§èƒ½
- å¯é€‰å®‰è£…ï¼ˆä¸å®‰è£…åˆ™ä½¿ç”¨ wetext ä½œä¸ºé»˜è®¤ï¼‰

---

### æ¨¡å‹é€‰æ‹©å»ºè®®

1. **è¿½æ±‚æœ€ä½³æ€§èƒ½**: é€‰æ‹© **CosyVoice2-0.5B**
2. **éœ€è¦è¯­éŸ³è½¬æ¢**: é€‰æ‹© **CosyVoice-300M**
3. **å›ºå®šéŸ³è‰²åœºæ™¯**: é€‰æ‹© **CosyVoice-300M-SFT**
4. **éœ€è¦æƒ…æ„Ÿæ§åˆ¶**: é€‰æ‹© **CosyVoice-300M-Instruct**
5. **èµ„æºå—é™ç¯å¢ƒ**: é€‰æ‹© **CosyVoice-300M-25Hz**

## å®‰è£…

### å…‹éš†å’Œå®‰è£…

- å…‹éš†ä»“åº“
    ``` sh
    git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
    # å¦‚æœç”±äºç½‘ç»œæ•…éšœæ— æ³•å…‹éš†å­æ¨¡å—ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ç›´åˆ°æˆåŠŸ
    cd CosyVoice
    git submodule update --init --recursive
    ```

- å®‰è£… Conda: è¯·å‚é˜… https://docs.conda.io/en/latest/miniconda.html
- åˆ›å»º Conda ç¯å¢ƒ:

    ``` sh
    conda create -n cosyvoice -y python=3.10
    conda activate cosyvoice
    pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com

    # å¦‚æœé‡åˆ° sox å…¼å®¹æ€§é—®é¢˜
    # ubuntu
    sudo apt-get install sox libsox-dev
    # centos
    sudo yum install sox sox-devel
    ```

### æ¨¡å‹ä¸‹è½½

æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨ä¸‹è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ `CosyVoice2-0.5B` `CosyVoice-300M` `CosyVoice-300M-SFT` `CosyVoice-300M-Instruct` ä»¥åŠ `CosyVoice-ttsfrd` èµ„æºã€‚

``` python
# SDK æ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
snapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')
snapshot_download('iic/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')
snapshot_download('iic/CosyVoice-300M-SFT', local_dir='pretrained_models/CosyVoice-300M-SFT')
snapshot_download('iic/CosyVoice-300M-Instruct', local_dir='pretrained_models/CosyVoice-300M-Instruct')
snapshot_download('iic/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')
```

``` sh
# git æ¨¡å‹ä¸‹è½½ï¼Œè¯·ç¡®ä¿å·²å®‰è£… git lfs
mkdir -p pretrained_models
git clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M
git clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git pretrained_models/CosyVoice-300M-SFT
git clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git pretrained_models/CosyVoice-300M-Instruct
git clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git pretrained_models/CosyVoice-ttsfrd

modelscope download --model iic/CosyVoice-300M-SFT --local_dir ./CosyVoice-300M-SFT
modelscope download --model iic/CosyVoice-300M-Instruct --local_dir ./CosyVoice-300M-Instruct
modelscope download --model iic/CosyVoice-ttsfrd --local_dir ./CosyVoice-ttsfrd

```

å¯é€‰åœ°ï¼Œæ‚¨å¯ä»¥è§£å‹ `ttsfrd` èµ„æºå¹¶å®‰è£… `ttsfrd` åŒ…ä»¥è·å¾—æ›´å¥½çš„æ–‡æœ¬è§„èŒƒåŒ–æ€§èƒ½ã€‚

æ³¨æ„ï¼šæ­¤æ­¥éª¤ä¸æ˜¯å¿…éœ€çš„ã€‚å¦‚æœæ‚¨ä¸å®‰è£… `ttsfrd` åŒ…ï¼Œæˆ‘ä»¬å°†é»˜è®¤ä½¿ç”¨ wetextã€‚

``` sh
cd pretrained_models/CosyVoice-ttsfrd/
unzip resource.zip -d .
pip install ttsfrd_dependency-0.1-py3-none-any.whl
pip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
```

### åŸºæœ¬ä½¿ç”¨

æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨ `CosyVoice2-0.5B` ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚
è¯·æŒ‰ç…§ä»¥ä¸‹ä»£ç äº†è§£æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ä½¿ç”¨æ–¹æ³•ã€‚

``` python
import sys
sys.path.append('third_party/Matcha-TTS')
from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
from cosyvoice.utils.file_utils import load_wav
import torchaudio
```

#### CosyVoice2 ä½¿ç”¨ç¤ºä¾‹
```python
cosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, load_vllm=False, fp16=False)

# æ³¨æ„ï¼šå¦‚æœæ‚¨æƒ³å¤ç° https://funaudiollm.github.io/cosyvoice2 ä¸Šçš„ç»“æœï¼Œè¯·åœ¨æ¨ç†æ—¶æ·»åŠ  text_frontend=False
# zero_shot ä½¿ç”¨
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# ä¿å­˜ zero_shot éŸ³è‰²ä»¥ä¾›å°†æ¥ä½¿ç”¨
assert cosyvoice.add_zero_shot_spk('å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, 'my_zero_shot_spk') is True
for i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', '', '', zero_shot_spk_id='my_zero_shot_spk', stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
cosyvoice.save_spkinfo()

# ç»†ç²’åº¦æ§åˆ¶ï¼Œæ”¯æŒçš„æ§ä»¶è¯·æŸ¥çœ‹ cosyvoice/tokenizer/tokenizer.py#L248
for i, j in enumerate(cosyvoice.inference_cross_lingual('åœ¨ä»–è®²è¿°é‚£ä¸ªè’è¯æ•…äº‹çš„è¿‡ç¨‹ä¸­ï¼Œä»–çªç„¶[laughter]åœä¸‹æ¥ï¼Œå› ä¸ºä»–è‡ªå·±ä¹Ÿè¢«é€—ç¬‘äº†[laughter]ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('fine_grained_control_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# instruct ä½¿ç”¨
for i, j in enumerate(cosyvoice.inference_instruct2('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'ç”¨å››å·è¯è¯´è¿™å¥è¯', prompt_speech_16k, stream=False)):
    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

# åŒå‘æµå¼ä½¿ç”¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ç”Ÿæˆå™¨ä½œä¸ºè¾“å…¥ï¼Œè¿™åœ¨å°†æ–‡æœ¬ LLM æ¨¡å‹ä½œä¸ºè¾“å…¥æ—¶å¾ˆæœ‰ç”¨
# æ³¨æ„ï¼šæ‚¨ä»ç„¶éœ€è¦ä¸€äº›åŸºæœ¬çš„å¥å­åˆ†å‰²é€»è¾‘ï¼Œå› ä¸º LLM æ— æ³•å¤„ç†ä»»æ„é•¿åº¦çš„å¥å­
def text_generator():
    yield 'æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œ'
    yield 'é‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦'
    yield 'è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œ'
    yield 'ç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚'
for i, j in enumerate(cosyvoice.inference_zero_shot(text_generator(), 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
```

#### CosyVoice2 vllm ä½¿ç”¨

å¦‚æœæ‚¨æƒ³ä½¿ç”¨ vllm è¿›è¡Œæ¨ç†ï¼Œè¯·å®‰è£… `vllm==v0.9.0`ã€‚æ—§ç‰ˆæœ¬çš„ vllm ä¸æ”¯æŒ CosyVoice2 æ¨ç†ã€‚

æ³¨æ„ï¼š`vllm==v0.9.0` æœ‰å¾ˆå¤šç‰¹å®šè¦æ±‚ï¼Œä¾‹å¦‚ `torch==2.7.0`ã€‚å¦‚æœæ‚¨çš„ç¡¬ä»¶ä¸æ”¯æŒ vllm æˆ–æ—§ç¯å¢ƒå·²æŸåï¼Œæ‚¨å¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°ç¯å¢ƒã€‚

``` sh
conda create -n cosyvoice_vllm --clone cosyvoice
conda activate cosyvoice_vllm
pip install vllm==v0.9.0 transformers==4.51.3 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
python vllm_example.py
```

#### CosyVoice ä½¿ç”¨ç¤ºä¾‹
```python
cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-SFT', load_jit=False, load_trt=False, fp16=False)
# sft ä½¿ç”¨
print(cosyvoice.list_available_spks())
# å°† stream=True ç”¨äºåˆ†å—æµå¼æ¨ç†
for i, j in enumerate(cosyvoice.inference_sft('ä½ å¥½ï¼Œæˆ‘æ˜¯é€šä¹‰ç”Ÿæˆå¼è¯­éŸ³å¤§æ¨¡å‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ', 'ä¸­æ–‡å¥³', stream=False)):
    torchaudio.save('sft_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M')
# zero_shot ä½¿ç”¨ï¼Œ<|zh|><|en|><|jp|><|yue|><|ko|> åˆ†åˆ«è¡¨ç¤ºä¸­æ–‡/è‹±æ–‡/æ—¥æ–‡/ç²¤è¯­/éŸ©æ–‡
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):
    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
# cross_lingual ä½¿ç”¨
prompt_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_cross_lingual('<|en|>And then later on, fully acquiring that company. So keeping management in line, interest in line with the asset that\'s coming into the family is a reason why sometimes we don\'t buy the whole thing.', prompt_speech_16k, stream=False)):
    torchaudio.save('cross_lingual_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
# vc ä½¿ç”¨
prompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)
source_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)
for i, j in enumerate(cosyvoice.inference_vc(source_speech_16k, prompt_speech_16k, stream=False)):
    torchaudio.save('vc_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)

cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-Instruct')
# instruct ä½¿ç”¨ï¼Œæ”¯æŒ <laughter></laughter><strong></strong>[laughter][breath]
for i, j in enumerate(cosyvoice.inference_instruct('åœ¨é¢å¯¹æŒ‘æˆ˜æ—¶ï¼Œä»–å±•ç°äº†éå‡¡çš„<strong>å‹‡æ°”</strong>ä¸<strong>æ™ºæ…§</strong>ã€‚', 'ä¸­æ–‡ç”·', 'Theo \'Crimson\', is a fiery, passionate rebel leader. Fights with fervor for justice, but struggles with impulsiveness.', stream=False)):
    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
```

#### å¯åŠ¨ Web æ¼”ç¤º

æ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„ Web æ¼”ç¤ºé¡µé¢å¿«é€Ÿç†Ÿæ‚‰ CosyVoiceã€‚

è¯·æŸ¥çœ‹æ¼”ç¤ºç½‘ç«™äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚

``` python
# ä½¿ç”¨ SFT æ¨ç†æ—¶æ”¹ä¸º iic/CosyVoice-300M-SFTï¼Œæˆ–ä½¿ç”¨ Instruct æ¨ç†æ—¶æ”¹ä¸º iic/CosyVoice-300M-Instruct
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M
```

#### GPU é€‰æ‹©åŠŸèƒ½

å¦‚æœæ‚¨çš„æœåŠ¡å™¨æœ‰å¤šä¸ª GPUï¼Œå¯ä»¥ä½¿ç”¨ `--gpu` å‚æ•°æŒ‡å®šä½¿ç”¨å“ªä¸ª GPU è®¾å¤‡ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
# ä½¿ç”¨ GPU 1ï¼ˆè€Œä¸æ˜¯é»˜è®¤çš„ GPU 0ï¼‰
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M --gpu 1

# ä½¿ç”¨ GPU 0ï¼ˆé»˜è®¤ï¼Œå¯ä»¥ä¸æŒ‡å®šï¼‰
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M --gpu 0

# ä¸æŒ‡å®š --gpu å‚æ•°æ—¶ï¼Œé»˜è®¤ä½¿ç”¨ GPU 0
python3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M
```

**å‚æ•°è¯´æ˜**:
- `--gpu`: GPU è®¾å¤‡ IDï¼ˆä¾‹å¦‚ 0 æˆ– 1ï¼‰ã€‚å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤ä½¿ç”¨ GPU 0
- ç³»ç»Ÿä¼šè‡ªåŠ¨éªŒè¯æŒ‡å®šçš„ GPU æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ä¼šæŠ¥é”™

**æ³¨æ„äº‹é¡¹**:
- ç¡®ä¿æŒ‡å®šçš„ GPU è®¾å¤‡å¯ç”¨
- å¦‚æœ CUDA ä¸å¯ç”¨ï¼Œç³»ç»Ÿä¼šå¿½ç•¥ `--gpu` å‚æ•°å¹¶ç»™å‡ºè­¦å‘Š
- æ‰€æœ‰ç›¸å…³ç»„ä»¶ï¼ˆPyTorchã€ONNX Runtimeï¼‰éƒ½ä¼šä½¿ç”¨æŒ‡å®šçš„ GPU

#### é«˜çº§ä½¿ç”¨

å¯¹äºé«˜çº§ç”¨æˆ·ï¼Œæˆ‘ä»¬åœ¨ `examples/libritts/cosyvoice/run.sh` ä¸­æä¾›äº†è®­ç»ƒå’Œæ¨ç†è„šæœ¬ã€‚

#### æ„å»ºéƒ¨ç½²ç‰ˆæœ¬

å¯é€‰åœ°ï¼Œå¦‚æœæ‚¨æƒ³è¦æœåŠ¡éƒ¨ç½²ï¼Œå¯ä»¥è¿è¡Œä»¥ä¸‹æ­¥éª¤ã€‚

``` sh
cd runtime/python
docker build -t cosyvoice:v1.0 .
# å¦‚æœè¦ä½¿ç”¨ instruct æ¨ç†ï¼Œå°† iic/CosyVoice-300M æ”¹ä¸º iic/CosyVoice-300M-Instruct
# ç”¨äº grpc ä½¿ç”¨
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/grpc && python3 server.py --port 50000 --max_conc 4 --model_dir iic/CosyVoice-300M && sleep infinity"
cd grpc && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>
# ç”¨äº fastapi ä½¿ç”¨
docker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c "cd /opt/CosyVoice/CosyVoice/runtime/python/fastapi && python3 server.py --port 50000 --model_dir iic/CosyVoice-300M && sleep infinity"
cd fastapi && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>
```

#### ä½¿ç”¨ Nvidia TensorRT-LLM è¿›è¡Œéƒ¨ç½²

ä½¿ç”¨ TensorRT-LLM åŠ é€Ÿ cosyvoice2 llm ç›¸æ¯” huggingface transformers å®ç°å¯ä»¥è·å¾— 4 å€åŠ é€Ÿã€‚
å¿«é€Ÿå¼€å§‹:

``` sh
cd runtime/triton_trtllm
docker compose up -d
```
æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹ [è¿™é‡Œ](https://github.com/FunAudioLLM/CosyVoice/tree/main/runtime/triton_trtllm)

## è®¨è®ºä¸äº¤æµ

æ‚¨å¯ä»¥ç›´æ¥åœ¨ [Github Issues](https://github.com/FunAudioLLM/CosyVoice/issues) ä¸Šè®¨è®ºã€‚

æ‚¨ä¹Ÿå¯ä»¥æ‰«æäºŒç»´ç åŠ å…¥æˆ‘ä»¬çš„å®˜æ–¹é’‰é’‰èŠå¤©ç¾¤ã€‚

<img src="./asset/dingding.png" width="250px">

## è‡´è°¢

1. æˆ‘ä»¬ä» [FunASR](https://github.com/modelscope/FunASR) å€Ÿé‰´äº†å¤§é‡ä»£ç ã€‚
2. æˆ‘ä»¬ä» [FunCodec](https://github.com/modelscope/FunCodec) å€Ÿé‰´äº†å¤§é‡ä»£ç ã€‚
3. æˆ‘ä»¬ä» [Matcha-TTS](https://github.com/shivammehta25/Matcha-TTS) å€Ÿé‰´äº†å¤§é‡ä»£ç ã€‚
4. æˆ‘ä»¬ä» [AcademiCodec](https://github.com/yangdongchao/AcademiCodec) å€Ÿé‰´äº†å¤§é‡ä»£ç ã€‚
5. æˆ‘ä»¬ä» [WeNet](https://github.com/wenet-e2e/wenet) å€Ÿé‰´äº†å¤§é‡ä»£ç ã€‚

## å¼•ç”¨

``` bibtex
@article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@article{du2024cosyvoice,
  title={Cosyvoice 2: Scalable streaming speech synthesis with large language models},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}

@article{du2025cosyvoice,
  title={CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training},
  author={Du, Zhihao and Gao, Changfeng and Wang, Yuxuan and Yu, Fan and Zhao, Tianyu and Wang, Hao and Lv, Xiang and Wang, Hui and Shi, Xian and An, Keyu and others},
  journal={arXiv preprint arXiv:2505.17589},
  year={2025}
}

@inproceedings{lyu2025build,
  title={Build LLM-Based Zero-Shot Streaming TTS System with Cosyvoice},
  author={Lyu, Xiang and Wang, Yuxuan and Zhao, Tianyu and Wang, Hao and Liu, Huadai and Du, Zhihao},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--2},
  year={2025},
  organization={IEEE}
}
```

## å…è´£å£°æ˜

ä¸Šè¿°å†…å®¹ä»…ä¾›å­¦æœ¯ç›®çš„ï¼Œæ—¨åœ¨å±•ç¤ºæŠ€æœ¯èƒ½åŠ›ã€‚éƒ¨åˆ†ç¤ºä¾‹æ¥æºäºäº’è”ç½‘ã€‚å¦‚æœ‰ä»»ä½•å†…å®¹ä¾µçŠ¯æ‚¨çš„æƒåˆ©ï¼Œè¯·è”ç³»æˆ‘ä»¬è¯·æ±‚åˆ é™¤ã€‚
